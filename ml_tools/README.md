# Machine Learning Tools for Depth Estimation

This directory contains a suite of Python scripts that form a complete pipeline for preparing data, fine-tuning a depth estimation model, and evaluating its performance on a custom endoscopic dataset.

## Workflow Overview

The process is divided into three main steps:

1.  **Split Dataset**: Prepare the raw dataset by splitting it into training, validation, and test sets.
2.  **Train Model**: Fine-tune a pre-trained `DepthAnythingV2` model on the prepared dataset.
3.  **Evaluate Model**: Assess the performance of the fine-tuned model against the original baseline and generate a report.

---

## Step 1: Split the Dataset for Training

### `1_split_for_training.py`

*   **Purpose**: This script takes the final, clean dataset generated by the preceding steps (located in `depth_data`) and organizes it into a structure suitable for PyTorch. It splits the data into `train`, `val`, and `test` sets based on hardcoded dataset IDs.
*   **Input**: The script reads from a source directory (e.g., `depth_data/endoscope/`).
*   **Output**: It creates a new directory (default: `pytorch_dataset_depth`) with the following structure, copying images (`_projected.png`), ground truth depth maps (`_depth.png`), and pose files (`.yml`) into their respective folders.

    ```
    pytorch_dataset_depth/
    ├── train/
    │   ├── gts/
    │   ├── images/
    │   └── poses/
    ├── val/
    │   ├── gts/
    │   ├── images/
    │   └── poses/
    └── test/
        ├── gts/
        ├── images/
        └── poses/
    ```
*   **Usage**:
    ```bash
    python ml_tools/1_split_for_training.py --source_dir depth_data --dest_dir pytorch_dataset_depth
    ```

---

## Step 2: Fine-Tune the Depth Model

### `2_train.py`

*   **Purpose**: This script handles the fine-tuning of the `DepthAnythingV2` model. It uses the `train` and `val` sets created in the previous step.
*   **Features**:
    *   Loads pre-trained `DepthAnythingV2` weights (`s`, `b`, or `l` variants).
    *   Uses a custom `DepthLoss` function combining L1 loss and a scale-invariant loss component.
    *   Supports gradient accumulation to simulate larger batch sizes.
    *   Logs training progress to both the console and a log file in the `logs/` directory.
    *   Saves the best-performing model checkpoint to the `checkpoints/` directory based on validation loss.
*   **Prerequisites**:
    *   The dataset must be split using `1_split_for_training.py`.
    *   Pre-trained model weights (e.g., `depth_anything_v2_vits.pth`) must be present in the `checkpoints/` directory.
*   **Usage**:
    ```bash
    python ml_tools/2_train.py --model_type s --epochs 20 --batch_size 4 --lr 1e-5
    ```
    *   `--model_type`: Choose from `s` (small), `b` (base), or `l` (large).
    *   Other arguments control hyperparameters like epochs, batch size, learning rate, etc.

---

## Step 3: Evaluate the Fine-Tuned Model

### `3_evaluate.py`

*   **Purpose**: This script evaluates the performance of the fine-tuned model using the `test` set. It provides a quantitative and qualitative comparison against the original, non-fine-tuned `DepthAnythingV2` model.
*   **Process**:
    1.  Loads both the fine-tuned model and the original pre-trained model.
    2.  For each sample in the test set, it generates depth predictions from both models.
    3.  The original model's output is aligned with the ground truth scale and shift for a fair comparison.
    4.  It computes standard depth estimation metrics (AbsRel, SQRel, RMSE, δ1, δ2, δ3).
*   **Output**: The script generates several outputs in the `evaluation_results/` directory:
    *   **Metrics CSV (`metrics_{model_type}.csv`)**: A detailed CSV file with performance metrics for every single image in the test set.
    *   **Report (`report_{model_type}.md`)**: A Markdown summary comparing the average metrics of the original vs. fine-tuned model, including percentage improvements.
    *   **Visualizations (`visualizations_{model_type}/`)**: A folder containing comparison images that show the RGB input, ground truth depth, original model prediction, and fine-tuned model prediction side-by-side for a random subset of the test data.
*   **Usage**:
    ```bash
    python ml_tools/3_evaluate.py --finetuned_checkpoint checkpoints/finetuned_s_best.pth --num_visualizations 20
    ```