#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Automated Pose Optimization for Depth Generation
==============================================
VERSION: 1.0

Description:
    This script performs an automated, parallelized alignment of camera poses to a master
    point cloud. It refines the initial poses generated by the manual offset step
    by using a coarse-to-fine grid search to maximize the edge-based similarity
    between a real endoscope image and a projected point cloud view.

Usage:
    python 3_optimize_poses.py --dataset DATASET_NAME --frame_start START --frame_end END [options]

"""

from concurrent.futures import ProcessPoolExecutor, as_completed
import numpy as np
import open3d as o3d
import cv2
import yaml
from scipy.spatial.transform import Rotation
import argparse
from pathlib import Path
import multiprocessing
from itertools import product
from functools import partial
import sys
import signal
import time
import logging
import os

# Assuming these modules are in the python path or same directory
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from dataset_config import DATASET_CONFIGS
from utilities.projection import project_point_cloud

# --- Logging and Configuration ---
def setup_logger():
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)
    if not logger.handlers:
        handler = logging.StreamHandler(sys.stdout)
        formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        handler.setFormatter(formatter)
        logger.addHandler(handler)
    return logger

logger = setup_logger()

# --- Signal Handling for Graceful Exit ---
def signal_handler(signum, frame):
    """Signal handler for graceful interruption handling."""
    logger.warning("Received interrupt signal. Cleaning up...")
    sys.exit(1)

signal.signal(signal.SIGINT, signal_handler)


# --- Core Processing Functions ---

def compute_edge_similarity(img1, img2):
    """Compute similarity between two images using Canny edge detection and absolute difference."""
    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY) if len(img1.shape) == 3 else img1
    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY) if len(img2.shape) == 3 else img2
    edges1 = cv2.Canny(img1_gray, 100, 200)
    edges2 = cv2.Canny(img2_gray, 100, 200)
    return np.mean(cv2.absdiff(edges1, edges2))

def create_comparison_image(real_image, initial_projected, final_projected):
    """Create a side-by-side comparison image with labels and blended results."""
    # Blend: 25% synthetic, 75% real
    initial_blend = cv2.addWeighted(real_image, 0.75, initial_projected, 0.25, 0)
    final_blend = cv2.addWeighted(real_image, 0.75, final_projected, 0.25, 0)
    font = cv2.FONT_HERSHEY_SIMPLEX
    cv2.putText(initial_blend, "Before Alignment", (10, 30), font, 1, (255, 255, 255), 2)
    cv2.putText(final_blend, "After Alignment", (10, 30), font, 1, (255, 255, 255), 2)
    return np.hstack([initial_blend, final_blend])

def process_combination(
    params,
    real_image,
    camera_matrix,
    dist_coeffs,
    initial_pose_matrix,
    points,
    colors,
    image_size,
    dataset_name,
):
    """Process a single combination of delta parameters for the grid search."""
    try:
        rx_delta, ry_delta, rz_delta, tx_delta, ty_delta, tz_delta = params

        delta_transform = np.eye(4)
        delta_transform[:3, :3] = Rotation.from_euler("xyz", [rx_delta, ry_delta, rz_delta], degrees=True).as_matrix()
        delta_transform[:3, 3] = [tx_delta, ty_delta, tz_delta]

        current_pose = initial_pose_matrix @ delta_transform

        current_projected = project_point_cloud(
            points, colors, camera_matrix, dist_coeffs, current_pose, image_size, dataset_name
        )

        score = compute_edge_similarity(real_image, current_projected)

        return {"score": score, "final_pose": current_pose, "deltas": params}
    except Exception as e:
        logger.error(f"Error in process_combination: {e}", exc_info=True)
        return {"score": float("inf"), "final_pose": initial_pose_matrix, "deltas": (0,0,0,0,0,0)}

def grid_search_alignment(
    real_image, camera_matrix, dist_coeffs, initial_pose_matrix, points, colors, image_size, dataset_name, translation_deltas, rotation_deltas
):
    """Perform a parallelized grid search to find the optimal alignment parameters."""
    all_combinations = list(product(rotation_deltas, rotation_deltas, rotation_deltas, translation_deltas, translation_deltas, translation_deltas))
    total_combinations = len(all_combinations)
    logger.info(f"Testing {total_combinations} combinations with Rot Deltas: {rotation_deltas}, Trans Deltas: {translation_deltas}")

    process_func = partial(
        process_combination,
        real_image=real_image,
        camera_matrix=camera_matrix,
        dist_coeffs=dist_coeffs,
        initial_pose_matrix=initial_pose_matrix,
        points=points,
        colors=colors,
        image_size=image_size,
        dataset_name=dataset_name,
    )

    # Use a ProcessPoolExecutor to run the grid search in parallel across multiple CPU cores.
    # This significantly speeds up the process by evaluating multiple pose combinations simultaneously.
    total_cpus = multiprocessing.cpu_count()
    reserved_cpus = 1 if total_cpus > 4 else 0
    num_workers = max(1, total_cpus - reserved_cpus)
    logger.info(f"System CPUs: {total_cpus}, Using {num_workers} worker processes.")

    all_results = []
    with ProcessPoolExecutor(max_workers=num_workers) as executor:
        # Submit all combinations to the process pool
        futures = [executor.submit(process_func, combo) for combo in all_combinations]
        
        # Collect results as they complete
        for i, future in enumerate(as_completed(futures)):
            try:
                all_results.append(future.result(timeout=90))
                print(f"\rProgress: {((i + 1) / total_combinations) * 100:.1f}%", end="", flush=True)
            except Exception as e:
                logger.error(f"A task failed or timed out: {e}")

    print() # Newline after progress bar
    if not all_results:
        raise RuntimeError("Grid search failed to produce any results.")

    return min(all_results, key=lambda x: x["score"])

def save_pose(matrix, file_path):
    """Saves a 4x4 transformation matrix to a YAML file in the correct format."""
    r = Rotation.from_matrix(matrix[:3, :3])
    quat = r.as_quat() # [x, y, z, w]
    pos_m = matrix[:3, 3] / 1000.0 # Convert back to meters

    output_data = {
        'pose': {
            'orientation': {'w': float(quat[3]), 'x': float(quat[0]), 'y': float(quat[1]), 'z': float(quat[2])},
            'position': {'x': float(pos_m[0]), 'y': float(pos_m[1]), 'z': float(pos_m[2])},
        }
    }
    with open(file_path, "w") as f:
        yaml.dump(output_data, f, default_flow_style=False)

# --- Main Frame Processing ---

def process_single_frame(frame_number, dataset, pcd_data, camera_matrix, dist_coeffs):
    """Process a single frame from loading to saving the final optimized pose."""
    frame_dir = Path(f"./raw_data/endoscope/{dataset}/frame{frame_number}")
    initial_pose_path = frame_dir / f"frame{frame_number}_initial.yml"
    image_path = frame_dir / f"frame{frame_number}.png"

    if not all([initial_pose_path.exists(), image_path.exists()]):
        logger.warning(f"Skipping frame {frame_number}: Missing initial pose or image file.")
        return False

    try:
        logger.info(f"Processing frame {frame_number}...")
        real_image = cv2.imread(str(image_path))
        image_size = (real_image.shape[0], real_image.shape[1])

        with open(initial_pose_path, "r") as f:
            initial_pose_data = yaml.safe_load(f)
        pos = initial_pose_data["pose"]["position"]
        quat = initial_pose_data["pose"]["orientation"]
        initial_pose_matrix = np.eye(4)
        initial_pose_matrix[:3, :3] = Rotation.from_quat([quat["x"], quat["y"], quat["z"], quat["w"]]).as_matrix()
        initial_pose_matrix[:3, 3] = [pos["x"] * 1000, pos["y"] * 1000, pos["z"] * 1000]

        initial_projected = project_point_cloud(
            pcd_data['points'], pcd_data['colors'], camera_matrix, dist_coeffs, initial_pose_matrix, image_size, dataset
        )

        # Coarse-to-fine grid search
        logger.info("  - Coarse alignment...")
        best_coarse = grid_search_alignment(real_image, camera_matrix, dist_coeffs, initial_pose_matrix, pcd_data['points'], pcd_data['colors'], image_size, dataset, [-2.0, 0, 2.0], [0])
        
        logger.info("  - Fine alignment...")
        best_fine = grid_search_alignment(real_image, camera_matrix, dist_coeffs, best_coarse["final_pose"], pcd_data['points'], pcd_data['colors'], image_size, dataset, [-1.0, 0, 1.0], [-0.5, 0, 0.5])

        logger.info(f"  - Best score for frame {frame_number}: {best_fine['score']:.4f}")

        # Save the final optimized pose
        output_file = frame_dir / f"frame{frame_number}_optimized.yml"
        save_pose(best_fine["final_pose"], output_file)
        logger.info(f"  - Saved optimized pose to: {output_file}")

        # Save comparison image
        final_projected = project_point_cloud(
            pcd_data['points'], pcd_data['colors'], camera_matrix, dist_coeffs, best_fine["final_pose"], image_size, dataset
        )
        comparison_image = create_comparison_image(real_image, initial_projected, final_projected)
        comparison_file = frame_dir / f"frame{frame_number}_comparison.png"
        cv2.imwrite(str(comparison_file), comparison_image)
        logger.info(f"  - Saved comparison image to: {comparison_file}")

        return True

    except Exception as e:
        logger.error(f"Failed to process frame {frame_number}: {e}", exc_info=True)
        return False

# --- Main Execution ---

def main():
    # Set multiprocessing start method for compatibility on Linux/macOS
    if sys.platform != "win32":
        multiprocessing.set_start_method("spawn", force=True)

    parser = argparse.ArgumentParser(description="Automated camera pose optimization.")
    parser.add_argument("--dataset", type=str, required=True, help="Dataset name.")
    parser.add_argument("--frame_start", type=int, required=True, help="Starting frame number.")
    parser.add_argument("--frame_end", type=int, required=True, help="Ending frame number.")
    parser.add_argument(
        "--point_cloud",
        type=str,
        default=None,
        help="Path to a specific point cloud file. Defaults to the transformed cloud for the dataset."
    )
    args = parser.parse_args()

    # Load the master point cloud used for alignment
    pcd_path = args.point_cloud
    if pcd_path is None:
        # Default to the transformed cloud, which is known to be aligned with frame 0
        pcd_path = f"./raw_data/point_clouds/{args.dataset}/transformed/pose0_transformed.ply"

    if not os.path.exists(pcd_path):
        logger.error(f"Master point cloud not found: {pcd_path}")
        logger.error("Please ensure you have run the point cloud transformation steps first.")
        sys.exit(1)

    logger.info(f"Loading master point cloud from: {pcd_path}")
    pcd = o3d.io.read_point_cloud(pcd_path)
    pcd_data = {
        'points': np.asarray(pcd.points),
        'colors': np.asarray(pcd.colors) if pcd.has_colors() else None
    }

    camera_matrix = np.array([[1.1573e03, 0, 1.0291e03], [0, 1.1562e03, 5.2774e02], [0, 0, 1]])
    dist_coeffs = np.array([[-0.489, 0.329, -0.001, -0.0001, -0.014]])

    start_time = time.time()
    frames_to_process = range(args.frame_start, args.frame_end + 1)
    
    # Process frames sequentially; parallelism is within each frame's grid search
    successful_frames = 0
    for frame_number in frames_to_process:
        if process_single_frame(frame_number, args.dataset, pcd_data, camera_matrix, dist_coeffs):
            successful_frames += 1
    
    logger.info(f"\n--- Optimization Complete in {time.time() - start_time:.2f}s ---")
    logger.info(f"Successfully processed {successful_frames}/{len(frames_to_process)} frames for dataset '{args.dataset}'.")

if __name__ == "__main__":
    main()
