#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HFD-3D Comprehensive Dataset Quality Validation Script
=====================================================
VERSION: 1.0

Description:
    This script provides a suite of tools to quantitatively validate the quality
    of the HFD-3D dataset. It supports analyzing groups of datasets and
    aggregates statistics across all their frames. It uses automated methods for
    planarity and reprojection error to ensure objective results.

Usage:
    # Analyze the 'ex-vivo' group using frame 150 for single-frame tests
    python run_quality_validation.py --dataset_root ./data_clean --dataset_group ex-vivo --sample_frame 150

    # Run only the reprojection test on dataset 2, using frame 100
    python run_quality_validation.py --dataset_root ./data_clean --dataset_group 2 --tests reprojection --sample_frame 100
"""

import os
import argparse
import cv2
import numpy as np
import open3d as o3d
import yaml
from scipy.ndimage import sobel
from matplotlib import pyplot as plt
from datetime import datetime
from math import sqrt

# --- Configuration ---

DATASET_CATEGORIES = {
    "basic": [str(i) for i in range(1, 7)],
    "advanced": [str(i) for i in range(7, 10)],
    "porous": [str(i) for i in range(10, 13)],
    "fabric": [str(i) for i in range(13, 22)],
    "ex-vivo": [str(i) for i in range(22, 28)],
}

DATASET_CROP_CONFIGS = {
    "default": {"mask_center": (1040, 550)}, "dataset1": {"mask_center": (1020, 555)},
    "dataset2": {"mask_center": (1025, 545)}, "dataset3": {"mask_center": (1028, 540)},
    "dataset4": {"mask_center": (1028, 545)}, "dataset5": {"mask_center": (1025, 555)},
    "dataset6": {"mask_center": (1025, 560)}, "dataset7": {"mask_center": (1025, 555)},
    "dataset8": {"mask_center": (1025, 555)}, "dataset9": {"mask_center": (1025, 555)},
    "dataset10": {"mask_center": (1025, 555)}, "dataset11": {"mask_center": (1025, 555)},
    "dataset12": {"mask_center": (1025, 545)}, "dataset13": {"mask_center": (1028, 555)},
    "dataset14": {"mask_center": (1028, 555)}, "dataset15": {"mask_center": (1028, 550)},
    "dataset16": {"mask_center": (1028, 550)}, "dataset17": {"mask_center": (1028, 550)},
    "dataset18": {"mask_center": (1028, 550)}, "dataset19": {"mask_center": (1028, 555)},
    "dataset20": {"mask_center": (1028, 550)}, "dataset21": {"mask_center": (1028, 550)},
    "dataset22": {"mask_center": (1028, 550)}, "dataset23": {"mask_center": (1025, 555)},
    "dataset24": {"mask_center": (1025, 545)}, "dataset25": {"mask_center": (1025, 545)},
    "dataset26": {"mask_center": (1025, 555)}, "dataset27": {"mask_center": (1025, 550)},
    "dataset28": {"mask_center": (1025, 550)},
}

# --- Helper Functions ---

def load_rgb(path):
    """Loads an RGB image from the specified path."""
    img = cv2.imread(path)
    if img is None: raise FileNotFoundError(f"Could not load RGB image at: {path}")
    return img

def load_depth(path):
    """Loads a depth map, converting it to millimeters."""
    depth = cv2.imread(path, cv2.IMREAD_UNCHANGED)
    if depth is None: raise FileNotFoundError(f"Could not load depth map at: {path}")
    return depth.astype(np.float32) / 65535.0 * 300.0

def load_pose(path):
    """Loads a 4x4 pose matrix from a YAML file."""
    with open(path, 'r') as f: data = yaml.safe_load(f)
    pos, quat = data['pose']['position'], data['pose']['orientation']
    T = np.eye(4)
    r = o3d.geometry.get_rotation_matrix_from_quaternion([quat['w'], quat['x'], quat['y'], quat['z']])
    T[:3, :3], T[:3, 3] = r, [pos['x']*1000, pos['y']*1000, pos['z']*1000]
    return T

def get_camera_intrinsics():
    """Returns the camera intrinsic matrix."""
    return np.array([[1.1573e03, 0, 1.0291e03], [0, 1.1562e03, 5.2774e02], [0, 0, 1]])

# --- Metric Calculation Functions ---

def calculate_icp_metrics(results_file):
    """Reports that ICP metrics should be generated by another script."""
    print("\n--- 1a. Geometric Fidelity: Inter-Scan Registration Error ---")
    results_file.write("\n--- 1a. Geometric Fidelity: Inter-Scan Registration Error ---\n")
    print("  NOTE: This metric must be generated by the `merge_point_clouds.py` script.")
    results_file.write("  See `icp_metrics.txt` generated by the merge script for actual values.\n")

def calculate_planarity_error(dataset_root, dataset_name, results_file):
    """Calculates the planarity error of the largest plane in a point cloud."""
    print("\n--- 1b. Geometric Fidelity: Automated Planarity Error ---")
    results_file.write("\n--- 1b. Geometric Fidelity: Automated Planarity Error ---\n")
    pcd_path = os.path.join(dataset_root, "point_clouds", dataset_name, "merged", "point_cloud.ply")
    if not os.path.exists(pcd_path):
        print(f"  ERROR: Master point cloud not found at {pcd_path}")
        results_file.write(f"  ERROR: Master point cloud not found at {pcd_path}\n")
        return

    print(f"  Loading master point cloud from {pcd_path}...")
    pcd = o3d.io.read_point_cloud(pcd_path)
    plane_model, inliers = pcd.segment_plane(distance_threshold=0.5, ransac_n=3, num_iterations=1000)
    
    if len(inliers) < 100:
        print("  ERROR: RANSAC could not find a significant plane. Test skipped.")
        results_file.write("  ERROR: RANSAC plane detection failed.\n")
        return

    plane_points = np.asarray(pcd.select_by_index(inliers).points)
    a, b, c, d = plane_model
    distances = np.abs(a*plane_points[:,0] + b*plane_points[:,1] + c*plane_points[:,2] + d) / np.sqrt(a**2 + b**2 + c**2)
    mean_error, std_error = np.mean(distances), np.std(distances)
    print(f"  RESULT: Mean planarity error on largest detected plane: {mean_error:.4f} mm (Std: {std_error:.4f} mm)")
    results_file.write(f"  Mean planarity error: {mean_error:.4f} mm (Std: {std_error:.4f} mm)\n")

def calculate_gradient_ncc(rgb_img, depth_map):
    """Calculates the Normalized Cross-Correlation between image and depth gradients."""
    gray_img = cv2.cvtColor(rgb_img, cv2.COLOR_BGR2GRAY)
    mask = depth_map > 0
    if np.sum(mask) < 100: return None

    grad_img_mag = np.sqrt(sobel(gray_img, 1, output=np.float64)**2 + sobel(gray_img, 0, output=np.float64)**2)
    grad_depth_mag = np.sqrt(sobel(depth_map, 1, output=np.float64)**2 + sobel(depth_map, 0, output=np.float64)**2)
    
    mean_img, mean_depth = np.mean(grad_img_mag[mask]), np.mean(grad_depth_mag[mask])
    numerator = np.sum((grad_img_mag[mask] - mean_img) * (grad_depth_mag[mask] - mean_depth))
    denominator = np.sqrt(np.sum((grad_img_mag[mask] - mean_img)**2) * np.sum((grad_depth_mag[mask] - mean_depth)**2))
    
    return numerator / denominator if denominator != 0 else 0

def calculate_reprojection_error(rgb_path, depth_path, pose_path, pcd_path, group_name, output_dir, results_file):
    """Calculates reprojection error by unprojecting and reprojecting keypoints."""
    print("\n--- 2b. Alignment Accuracy: Automated Keypoint Reprojection Error ---")
    results_file.write("\n--- 2b. Alignment Accuracy: Automated Keypoint Reprojection Error ---\n")

    rgb_img_cropped = load_rgb(rgb_path)
    depth_map_cropped = load_depth(depth_path)
    pose = load_pose(pose_path)
    pcd = o3d.io.read_point_cloud(pcd_path)
    pcd_tree = o3d.geometry.KDTreeFlann(pcd)

    K_original = get_camera_intrinsics()
    fx_orig, fy_orig = K_original[0, 0], K_original[1, 1]
    cx_orig, cy_orig = K_original[0, 2], K_original[1, 2]
    full_image_size = (2048, 1088)

    dataset_name_from_path = next((name for name in DATASET_CROP_CONFIGS if name in rgb_path), "default")
    config = DATASET_CROP_CONFIGS[dataset_name_from_path]
    center_x_mask, center_y_mask = config["mask_center"]
    radius = 635
    square_size = int((2 * radius) / sqrt(2))
    crop_origin_x = center_x_mask - (square_size // 2)
    crop_origin_y = center_y_mask - (square_size // 2)

    print("  Detecting keypoints in cropped RGB image...")
    gray_img_cropped = cv2.cvtColor(rgb_img_cropped, cv2.COLOR_BGR2GRAY)
    orb = cv2.ORB_create(nfeatures=500)
    keypoints_2d_cropped = orb.detect(gray_img_cropped, None)[:10]
    if not keypoints_2d_cropped:
        print("  ERROR: No keypoints detected.")
        results_file.write("  ERROR: No keypoints detected.\n")
        return

    print("  Unprojecting keypoints to 3D...")
    keypoints_3d_gt = []
    valid_keypoints_2d_cropped = []
    # 1. Unproject the 2D keypoint from the cropped image to the full, unrotated image space.
    for kp in keypoints_2d_cropped:
        u_crop, v_crop = int(kp.pt[0]), int(kp.pt[1])

        if not (0 <= v_crop < depth_map_cropped.shape[0] and 0 <= u_crop < depth_map_cropped.shape[1]):
            continue
        z = depth_map_cropped[v_crop, u_crop]
        if z < 10: continue # Ignore points that are too close

        # 2. Convert from cropped coordinates to full-size image coordinates
        u_full_rot = u_crop + crop_origin_x
        v_full_rot = v_crop + crop_origin_y
        
        # 3. Account for the 180-degree rotation applied during projection
        u_full_unrot = full_image_size[0] - u_full_rot
        v_full_unrot = full_image_size[1] - v_full_rot
        
        # 4. Back-project the 2D point to a 3D point in the camera's coordinate system
        x_cam = (u_full_unrot - cx_orig) * z / fx_orig
        y_cam = (v_full_unrot - cy_orig) * z / fy_orig
        p_cam = np.array([x_cam, y_cam, z, 1.0])
        
        # 5. Transform the 3D camera point to the world coordinate system
        p_world = (pose @ p_cam)[:3]

        # 6. Find the closest point in the ground truth point cloud to this unprojected point
        [k, idx, _] = pcd_tree.search_knn_vector_3d(p_world, 1)
        if k > 0:
            keypoints_3d_gt.append(np.asarray(pcd.points)[idx[0], :])
            valid_keypoints_2d_cropped.append(kp.pt)

    if not valid_keypoints_2d_cropped:
        print("  ERROR: No valid keypoints could be unprojected.")
        results_file.write("  ERROR: No valid keypoints.\n")
        return
    print(f"  Using {len(valid_keypoints_2d_cropped)} strongest keypoints for testing.")

    print("  Reprojecting ground truth points...")
    world_to_cam = np.linalg.inv(pose)
    rvec, _ = cv2.Rodrigues(world_to_cam[:3, :3])
    tvec = world_to_cam[:3, 3]
    
    reprojected_pts_full_unrot, _ = cv2.projectPoints(np.ascontiguousarray(keypoints_3d_gt), rvec, tvec, K_original, None)
    reprojected_pts_full_unrot = reprojected_pts_full_unrot.reshape(-1, 2)

    reprojected_pts_full_rot_x = full_image_size[0] - reprojected_pts_full_unrot[:, 0]
    reprojected_pts_full_rot_y = full_image_size[1] - reprojected_pts_full_unrot[:, 1]

    final_reprojected_pts_x = reprojected_pts_full_rot_x - crop_origin_x
    final_reprojected_pts_y = reprojected_pts_full_rot_y - crop_origin_y
    final_reprojected_pts = np.vstack((final_reprojected_pts_x, final_reprojected_pts_y)).T

    errors = [np.linalg.norm(np.array(p2d) - rp) for p2d, rp in zip(valid_keypoints_2d_cropped, final_reprojected_pts)]
    mean_error, std_error = np.mean(errors), np.std(errors)
    print(f"  RESULT: Mean Reprojection Error: {mean_error:.4f} pixels (Std: {std_error:.4f})")
    results_file.write(f"  Mean Reprojection Error: {mean_error:.4f} pixels (Std: {std_error:.4f})\n")

    h, w, _ = rgb_img_cropped.shape
    plt.figure(figsize=(10, 10 * h / w))
    plt.imshow(cv2.cvtColor(rgb_img_cropped, cv2.COLOR_BGR2RGB))
    indices_to_plot = np.random.choice(len(valid_keypoints_2d_cropped), min(10, len(valid_keypoints_2d_cropped)), replace=False)
    for i in indices_to_plot:
        x1, y1 = valid_keypoints_2d_cropped[i]
        x2, y2 = final_reprojected_pts[i]
        plt.plot([x1, x2], [y1, y2], 'y-')
        plt.scatter(x1, y1, c='lime', marker='o', s=25, label='Original Keypoint' if i==indices_to_plot[0] else "")
        plt.scatter(x2, y2, c='red', marker='x', s=25, label='Reprojected Point' if i==indices_to_plot[0] else "")
    plt.title(f'Automated Reprojection Error (Mean: {mean_error:.2f} px)', fontsize=16)
    plt.legend()
    plot_path = os.path.join(output_dir, f"automated_reprojection_error_{group_name}.png")
    plt.savefig(plot_path)
    plt.close()
    print(f"  Plot saved to: {plot_path}")
    results_file.write(f"  Plot saved to: {plot_path}\n")

def calculate_depth_density(depth_map):
    """Calculates the percentage of valid pixels in a depth map."""
    if depth_map.size == 0: return None
    return (np.sum(depth_map > 0) / depth_map.size) * 100

def calculate_depth_noise(rgb_img, depth_map):
    """Calculates the standard deviation of depth values in a user-selected planar region."""
    print("\n--- 3b. Depth Map Quality: Noise on Planar Surfaces ---")
    print("  INSTRUCTION: In the window, draw a rectangle over a known planar surface.")
    print("               Press 'Enter' or 'Space' to finalize.")
    
    roi = cv2.selectROI("Planar Region Selection", rgb_img)
    cv2.destroyAllWindows()
    
    if roi[2] == 0 or roi[3] == 0:
        print("  INFO: Invalid ROI selected. Test skipped.")
        return None
        
    x, y, w, h = [int(v) for v in roi]
    valid_depths = depth_map[y:y+h, x:x+w][depth_map[y:y+h, x:x+w] > 0]
    
    if len(valid_depths) < 10:
        print("  ERROR: Not enough valid depth points in the selected region.")
        return None
        
    return np.std(valid_depths)

def plot_aggregated_metrics_boxplot(data, title, ylabel, group_name, output_dir):
    """Generates and saves a box plot for a given metric."""
    if not data:
        print(f"Warning: No data to plot for {title}")
        return None
    plt.figure(figsize=(8, 6))
    plt.boxplot(data, vert=True, patch_artist=True, labels=[group_name])
    plt.title(title, fontsize=16)
    plt.ylabel(ylabel, fontsize=12)
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.tight_layout()
    plot_path = os.path.join(output_dir, f"boxplot_{title.replace(' ', '_').lower()}_{group_name}.png")
    plt.savefig(plot_path)
    plt.close()
    return plot_path

def report_calibration_quality(results_file):
    """Reports the intrinsic calibration reprojection error."""
    print("\n--- 4b. Dataset Statistics: Intrinsic Calibration Quality ---")
    results_file.write("\n--- 4b. Dataset Statistics: Intrinsic Calibration Quality ---\n")
    print("  INFO: This metric comes from the intrinsic calibration script.")
    reproj_error = 0.0
    print(f"  Camera calibration reprojection error: {reproj_error:.4f} pixels.")
    results_file.write(f"  Reprojection Error: {reproj_error:.4f} pixels.\n")

def save_qualitative_sample(rgb_path, depth_path, group_name, output_dir, results_file):
    """Saves a combined image showing RGB, depth, and an overlay."""
    print("\n--- 5a. Qualitative Analysis: Sample Figure ---")
    results_file.write("\n--- 5a. Qualitative Analysis: Sample Figure ---\n")
    rgb = load_rgb(rgb_path)
    depth = load_depth(depth_path)
    
    depth_color = cv2.normalize(depth, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)
    depth_color = cv2.applyColorMap(depth_color, cv2.COLORMAP_JET)
    depth_color[depth == 0] = 0
    
    overlay = cv2.addWeighted(rgb, 0.6, depth_color, 0.4, 0)
    
    h, w, _ = rgb.shape
    combined_img = np.zeros((h, w*3, 3), dtype=np.uint8)
    combined_img[:, :w] = rgb
    combined_img[:, w:w*2] = depth_color
    combined_img[:, w*2:] = overlay
    
    cv2.putText(combined_img, "RGB", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
    cv2.putText(combined_img, "Depth Map", (w + 10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
    cv2.putText(combined_img, "Overlay", (w*2 + 10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
    
    plot_path = os.path.join(output_dir, f"qualitative_sample_{group_name}.png")
    cv2.imwrite(plot_path, combined_img)
    print(f"  RESULT: Qualitative sample saved to {plot_path}")
    results_file.write(f"  Sample figure saved to: {plot_path}\n")

def calculate_depth_completeness_vs_distance(sample_frames, group_name, output_dir, results_file):
    """Plots a histogram of valid depth points as a function of distance."""
    print("\n--- 5b. Advanced Analysis: Depth Completeness vs. Distance ---")
    results_file.write("\n--- 5b. Advanced Analysis: Depth Completeness vs. Distance ---\n")
    
    bins = np.linspace(0, 300, 11)
    bin_centers = (bins[:-1] + bins[1:]) / 2
    
    all_depths = []
    for frame_data in sample_frames:
        depth = load_depth(frame_data['depth_path'])
        all_depths.extend(depth[depth > 0])
        
    counts, _ = np.histogram(all_depths, bins=bins)
    
    plt.figure(figsize=(12, 7))
    plt.bar(bin_centers, counts, width=25, color='skyblue', edgecolor='black')
    plt.title(f'Valid Depth Point Count vs. Distance - Group: {group_name}', fontsize=16)
    plt.xlabel('Distance from Camera (mm)', fontsize=12)
    plt.ylabel('Number of Valid Pixels (in sample)', fontsize=12)
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    plt.tight_layout()
    plot_path = os.path.join(output_dir, f"completeness_vs_distance_{group_name}.png")
    plt.savefig(plot_path)
    plt.close()
    print(f"  RESULT: Plot saved to {plot_path}")
    results_file.write(f"  Plot saved to: {plot_path}\n")

# --- Main Execution ---

def main():
    """Main function to parse arguments and run the validation tests."""
    parser = argparse.ArgumentParser(description="HFD-3D Dataset Quality Validation Script")
    parser.add_argument("--dataset_root", type=str, required=True, help="Path to the 'depth_data' directory.")
    parser.add_argument("--dataset_group", nargs='+', required=True, help="A category keyword or a list of dataset numbers.")
    parser.add_argument("--tests", nargs='+', default=["all"], help="List of tests to run.")
    parser.add_argument("--sample_frame", type=int, default=1, help="Frame number to use for single-frame validation tests. Default: 1")
    args = parser.parse_args()

    run_timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    output_dir = os.path.join("results", run_timestamp)
    os.makedirs(output_dir, exist_ok=True)
    results_file_path = os.path.join(output_dir, "summary_results.txt")

    if len(args.dataset_group) == 1 and args.dataset_group[0] in DATASET_CATEGORIES:
        group_name = args.dataset_group[0]
        dataset_numbers = DATASET_CATEGORIES[group_name]
    else:
        group_name = f"custom_group_{'_'.join(args.dataset_group)}"
        dataset_numbers = args.dataset_group
    
    dataset_names = [f"dataset{num}" for num in dataset_numbers]
    
    with open(results_file_path, 'w') as results_file:
        header = f"Quality Validation Report for Group: {group_name} ({len(dataset_names)} datasets)\n"
        results_file.write(header)
        
        run_all = "all" in args.tests
        
        all_frames = []
        for name in dataset_names:
            dataset_path = os.path.join(args.dataset_root, "endoscope", name)
            if not os.path.isdir(dataset_path): continue
            for frame_id in range(1, 513): 
                frame_dir = os.path.join(dataset_path, f"frame{frame_id}")
                rgb_path = os.path.join(frame_dir, f"frame{frame_id}.png")
                depth_path = os.path.join(frame_dir, f"frame{frame_id}_depth.png")
                pose_path = os.path.join(frame_dir, f"frame{frame_id}.yml")
                if os.path.exists(rgb_path) and os.path.exists(depth_path) and os.path.exists(pose_path):
                    all_frames.append({
                        "rgb_path": rgb_path, "depth_path": depth_path,
                        "pose_path": pose_path, "dataset": name
                    })
        
        if not all_frames:
            print(f"ERROR: No valid frames found for group '{group_name}'. Check paths in '{args.dataset_root}'.")
            return

        sample_frame_number = args.sample_frame
        first_dataset_name = dataset_names[0]
        
        sample_frame_paths = None
        for frame in all_frames:
            frame_num_in_path = int(os.path.basename(frame['rgb_path']).split('.')[0].replace('frame',''))
            if frame['dataset'] == first_dataset_name and frame_num_in_path == sample_frame_number:
                sample_frame_paths = frame
                break
        
        if sample_frame_paths is None:
            print(f"\nWARNING: Frame {sample_frame_number} not found for dataset {first_dataset_name}.")
            print("         Falling back to the first available frame for single-frame tests.")
            sample_frame_paths = all_frames[0]
        else:
            print(f"\nINFO: Using frame {sample_frame_number} from dataset {first_dataset_name} for single-frame tests.")
        
        # For memory-intensive aggregate plots, it uses a representative sample of frames.
        sample_frames_for_agg = all_frames
        if len(all_frames) > 100:
            print(f"\nINFO: Dataset group has {len(all_frames)} frames. Using a random sample of 100 for aggregate plots to conserve memory.")
            indices = np.random.choice(len(all_frames), 100, replace=False)
            sample_frames_for_agg = [all_frames[i] for i in indices]

        if run_all or "planarity" in args.tests:
            calculate_planarity_error(args.dataset_root, first_dataset_name, results_file)
        
        if run_all or "reprojection" in args.tests:
            pcd_path = os.path.join(args.dataset_root, "point_clouds", first_dataset_name, "merged", "point_cloud.ply")
            if os.path.exists(pcd_path):
                calculate_reprojection_error(sample_frame_paths['rgb_path'], sample_frame_paths['depth_path'], sample_frame_paths['pose_path'], pcd_path, group_name, output_dir, results_file)
            else:
                print(f"\nERROR: Master point cloud not found at {pcd_path}. Reprojection test skipped.")
                results_file.write("\nERROR: Master point cloud not found. Reprojection test skipped.\n")

        all_ncc_scores, all_densities = [], []
        
        histogram_bins = np.zeros(150)
        bin_edges = np.linspace(0, 300, 151)
        
        print(f"\nProcessing {len(all_frames)} frames for automated metrics...")
        
        for i, frame_data in enumerate(all_frames):
            print(f"\r  Analyzing {frame_data['dataset']} frame {i+1}/{len(all_frames)}...", end="")
            try:
                rgb = load_rgb(frame_data['rgb_path'])
                depth = load_depth(frame_data['depth_path'])
                if run_all or "gradient_ncc" in args.tests:
                    ncc = calculate_gradient_ncc(rgb, depth)
                    if ncc is not None: all_ncc_scores.append(ncc)
                if run_all or "density" in args.tests:
                    density = calculate_depth_density(depth)
                    if density is not None: all_densities.append(density)
                if (run_all or "histogram" in args.tests):
                    valid_depths = depth[depth > 0]
                    counts, _ = np.histogram(valid_depths, bins=bin_edges)
                    histogram_bins += counts
            except Exception as e:
                print(f"\n  Warning: Could not process frame {frame_data['rgb_path']}. Error: {e}")
                continue
        print("\nAutomated analysis complete.")

        if (run_all or "gradient_ncc" in args.tests) and all_ncc_scores:
            print("\n--- 2a. Alignment Accuracy: Aggregated Gradient NCC ---")
            results_file.write("\n--- 2a. Alignment Accuracy: Aggregated Gradient NCC ---\n")
            stats_text = f"  Mean: {np.mean(all_ncc_scores):.4f}, Std: {np.std(all_ncc_scores):.4f}, Median: {np.median(all_ncc_scores):.4f}"
            print(stats_text)
            results_file.write(stats_text + "\n")
            plot_path = plot_aggregated_metrics_boxplot(all_ncc_scores, "Gradient NCC", "NCC Value", group_name, output_dir)
            if plot_path: results_file.write(f"  Box plot saved to: {plot_path}\n")

        if (run_all or "density" in args.tests) and all_densities:
            print("\n--- 3a. Depth Map Quality: Aggregated Density ---")
            results_file.write("\n--- 3a. Depth Map Quality: Aggregated Density ---\n")
            stats_text = f"  Mean: {np.mean(all_densities):.2f}%, Std: {np.std(all_densities):.2f}%, Median: {np.median(all_densities):.2f}%"
            print(stats_text)
            results_file.write(stats_text + "\n")
            plot_path = plot_aggregated_metrics_boxplot(all_densities, "Depth Density", "Density (%)", group_name, output_dir)
            if plot_path: results_file.write(f"  Box plot saved to: {plot_path}\n")
        
        if "noise" in args.tests:
             rgb_img = load_rgb(sample_frame_paths['rgb_path'])
             depth_map = load_depth(sample_frame_paths['depth_path'])
             noise_val = calculate_depth_noise(rgb_img, depth_map)
             results_file.write("\n--- 3b. Depth Map Quality: Noise on Planar Surfaces ---\n")
             if noise_val is not None:
                 print(f"  RESULT: Depth noise (std dev) on sample plane: {noise_val:.4f} mm")
                 results_file.write(f"  Sample Depth Noise (std dev): {noise_val:.4f} mm\n")

        if (run_all or "histogram" in args.tests):
            print("\n--- 4a. Dataset Statistics: Depth Distribution ---")
            results_file.write("\n--- 4a. Dataset Statistics: Depth Distribution ---\n")
            plt.figure(figsize=(12, 7))
            plt.bar((bin_edges[:-1] + bin_edges[1:]) / 2, histogram_bins, width=2, color='teal')
            plt.title(f'Depth Value Distribution - Group: {group_name}', fontsize=16)
            plt.xlabel('Depth (mm)', fontsize=12)
            plt.ylabel('Frequency', fontsize=12)
            plt.grid(True, linestyle='--', alpha=0.6)
            plt.tight_layout()
            plot_path = os.path.join(output_dir, f"histogram_{group_name}.png")
            plt.savefig(plot_path)
            plt.close()
            print(f"  RESULT: Histogram saved to {plot_path}")
            results_file.write(f"  Histogram plot saved to: {plot_path}\n")
        
        calculate_icp_metrics(results_file)
        report_calibration_quality(results_file)
        save_qualitative_sample(sample_frame_paths['rgb_path'], sample_frame_paths['depth_path'], group_name, output_dir, results_file)
        calculate_depth_completeness_vs_distance(sample_frames_for_agg, group_name, output_dir, results_file)

        final_msg = f"\nValidation Complete. Results saved to: {output_dir}"
        print(final_msg)
        results_file.write(f"\n{final_msg}\n")

if __name__ == "__main__":
    main()
